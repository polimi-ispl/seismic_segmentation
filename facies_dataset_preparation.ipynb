{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load specific sections, apply preprocessing, extract patches and save on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import pandas as pd\n",
    "from patch_extractor import PatchExtractor as PE\n",
    "from utils import normalize_only, compute_edges\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = [\"Basement\", \"SlopeMudA\", \"Deposit\", \"SlopeMudB\", \"SlopeValley\", \"Canyon\"]\n",
    "num_classes = len(CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"/nas/public/dataset/geophysics/2020_aicrowd_facies_segmentation_challenge/\"\n",
    "out_root = \"/nas/home/fpicetti/datasets/seismic_facies/\"\n",
    "os.makedirs(out_root, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.load(os.path.join(dataset, \"data_train.npz\"), allow_pickle=True, mmap_mode='r')\n",
    "image =  image['data']\n",
    "label = np.load(os.path.join(dataset, \"labels_train.npz\"), allow_pickle=True, mmap_mode='r')\n",
    "label = label['labels'].astype(np.uint8)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z\tx\ty\n",
      "1006\t782\t590\n"
     ]
    }
   ],
   "source": [
    "print('z\\tx\\ty')\n",
    "print('%d\\t%d\\t%d' % (image.shape[0],image.shape[1],image.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = lambda x: normalize_only(x, image.min(), image.max(), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vertical $992\\times128$ patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = PE(dim=(992,128), stride=(2,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving patches extracted from XZ sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(out_root, \"_\".join([str(_) for _ in pe.dim+pe.stride]))\n",
    "os.makedirs(out_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inline section: 100%|███████████████████████████████████| 590/590 [29:01<00:00,  2.95s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in trange(image.shape[2], ncols=90, desc=\"Inline section\"):\n",
    "    patches_img = normalize(pe.extract(image[:,:,i]).reshape((-1,)+pe.dim+(1,)))\n",
    "    patches_msk = to_categorical(pe.extract(label[:,:,i]).reshape((-1,)+pe.dim+(1,)))\n",
    "    \n",
    "    for p in range(patches_img.shape[0]):\n",
    "        outname = os.path.join(out_path, \"XZ%s_p%s.npy\" % (str(i).zfill(3), str(p).zfill(len(str(patches_img.shape[0])))))\n",
    "        \n",
    "        np.save(outname, dict(image=patches_img[p], mask=patches_msk[p]), allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Crossline section:  15%|████▋                           | 114/782 [04:23<26:55,  2.42s/it]"
     ]
    }
   ],
   "source": [
    "for i in trange(image.shape[1], ncols=90, desc=\"Crossline section\"):\n",
    "    patches_img = normalize(pe.extract(image[:,i]).reshape((-1,)+pe.dim+(1,)))\n",
    "    patches_msk = to_categorical(pe.extract(label[:,i]).reshape((-1,)+pe.dim+(1,)))\n",
    "    \n",
    "    for p in range(patches_img.shape[0]):\n",
    "        outname = os.path.join(out_path, \"YZ%s_p%s.npy\" % (str(i).zfill(3), str(p).zfill(len(str(patches_img.shape[0])))))\n",
    "        \n",
    "        np.save(outname, dict(image=patches_img[p], mask=patches_msk[p]), allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create different pandas dataframes for train/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sections_train = 128\n",
    "num_sections_val = 64\n",
    "num_patches_per_section = len(glob.glob(os.path.join(out_path, \"XZ000_*.npy\")))\n",
    "train_start_section = 0\n",
    "val_start_section = 300\n",
    "\n",
    "train_idx0 = train_start_section*num_patches_per_section\n",
    "train_idx1 = train_idx0 + num_sections_train*num_patches_per_section\n",
    "\n",
    "val_idx0 = val_start_section*num_patches_per_section\n",
    "val_idx1 = val_idx0 + num_sections_val*num_patches_per_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = sorted(glob.glob(os.path.join(out_path, \"XZ*.npy\")))[train_idx0:train_idx1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_paths = sorted(glob.glob(os.path.join(out_path, \"XZ*.npy\")))[val_idx0:val_idx1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "df['datapath'] = train_paths + val_paths\n",
    "df['mode'] = len(train_paths)*['train'] + len(val_paths)*['val']\n",
    "df = pd.DataFrame.from_dict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(out_root, 'train1.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
