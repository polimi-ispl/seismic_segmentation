{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load specific sections, apply preprocessing, extract patches and save on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from patch_extractor import PatchExtractor as PE\n",
    "from utils import normalize_only\n",
    "from keras_data import _compute_edges\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = [\"Basement\", \"SlopeMudA\", \"Deposit\", \"SlopeMudB\", \"SlopeValley\", \"Canyon\"]\n",
    "num_classes = len(CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"/nas/public/dataset/geophysics/BlindTestSEG/\"\n",
    "out_root = \"/nas/home/fpicetti/datasets/seg_blind_test\"\n",
    "os.makedirs(out_root, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.load(os.path.join(dataset, \"train_image.npy\"))\n",
    "label = np.load(os.path.join(dataset, \"train_labels.npy\")).astype(np.uint8)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\ty\tz\n",
      "590\t782\t1006\n"
     ]
    }
   ],
   "source": [
    "print('x\\ty\\tz')\n",
    "print('%d\\t%d\\t%d' % (image.shape[0],image.shape[1],image.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = lambda x: normalize_only(x, image.min(), image.max(), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vertical $992\\times128$ patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = PE(dim=(992,128), stride=(2,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving patches extracted from XZ sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(out_root, \"normalized_categorical\", \"_\".join([str(_) for _ in pe.dim+pe.stride]))\n",
    "os.makedirs(out_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inline section: 100%|███████████████████████████████████| 782/782 [31:26<00:00,  2.41s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in trange(image.shape[1], ncols=90, desc=\"Inline section\"):\n",
    "    patches_img = normalize(pe.extract(image[:,i].T).reshape((-1,)+pe.dim+(1,)))\n",
    "    patches_msk = to_categorical(pe.extract(label[:,i].T).reshape((-1,)+pe.dim+(1,)))\n",
    "    patches_edg = _compute_edges(patches_msk)\n",
    "    \n",
    "    for p in range(patches_img.shape[0]):\n",
    "        outname = os.path.join(out_path, \"XZ%s_p%s.npy\" % (str(i).zfill(3), str(p).zfill(len(str(patches_img.shape[0])))))\n",
    "        \n",
    "        np.save(outname, dict(img=patches_img[p], msk=patches_msk[p]), allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Crossline section: 100%|████████████████████████████████| 590/590 [32:40<00:00,  3.32s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in trange(image.shape[0], ncols=90, desc=\"Crossline section\"):\n",
    "    patches_img = normalize(pe.extract(image[i].T).reshape((-1,)+pe.dim+(1,)))\n",
    "    patches_msk = to_categorical(pe.extract(label[i].T).reshape((-1,)+pe.dim+(1,)))\n",
    "    patches_edg = _compute_edges(patches_msk)\n",
    "    \n",
    "    for p in range(patches_img.shape[0]):\n",
    "        outname = os.path.join(out_path, \"YZ%s_p%s.npy\" % (str(i).zfill(3), str(p).zfill(len(str(patches_img.shape[0])))))\n",
    "        \n",
    "        np.save(outname, dict(img=patches_img[p], msk=patches_msk[p]), allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
